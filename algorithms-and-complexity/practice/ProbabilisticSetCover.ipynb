{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5dd45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.optimize as spo\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829f1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateInstance(m, n=10, maxW=100):\n",
    "    res=[]\n",
    "    for i in range(m):\n",
    "        s = set(random.sample(range(n), random.randint(1, n//m)))\n",
    "        res.append((s, random.randint(1, maxW)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97baf1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=generateInstance(5, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00558471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCover(I, k):\n",
    "    m = len(I)\n",
    "    universe = set.union(*[e for e,w in I])\n",
    "    n = len(universe)\n",
    "    # Objective function\n",
    "    c = np.array([w for e,w in I])\n",
    "    A_ub = np.zeros((n + m, m))\n",
    "    b_ub = np.zeros(n + m)\n",
    "    # Constraint: x[i]<=1\n",
    "    for i in range(m):\n",
    "        A_ub[i,i] = 1\n",
    "        b_ub[i] = 1\n",
    "    # Constaints\n",
    "    j = m\n",
    "    for u in universe:\n",
    "        for i in range(m):\n",
    "            if u in I[i][0]:\n",
    "                A_ub[j, i] = -1\n",
    "        b_ub[j] = -1\n",
    "        j += 1\n",
    "    lp = spo.linprog(c, A_ub, b_ub)\n",
    "    xhat = lp.x\n",
    "    #lpi = spo.linprog(c, A_ub, b_ub, integrality=[1 for i in range(m)])\n",
    "    Ires = set([])\n",
    "    for t in range(int(math.ceil(k + math.log(n)))):\n",
    "        for i in range(m):\n",
    "            if random.random() < xhat[i]:\n",
    "                Ires = Ires | set([i])\n",
    "    v = sum([I[i][1] for i in Ires])\n",
    "    return Ires, v#, lpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81138e27",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linprog() got an unexpected keyword argument 'integrality'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msetCover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36msetCover\u001b[0;34m(I, k)\u001b[0m\n\u001b[1;32m     21\u001b[0m lp \u001b[38;5;241m=\u001b[39m spo\u001b[38;5;241m.\u001b[39mlinprog(c, A_ub, b_ub)\n\u001b[1;32m     22\u001b[0m xhat \u001b[38;5;241m=\u001b[39m lp\u001b[38;5;241m.\u001b[39mx\n\u001b[0;32m---> 23\u001b[0m lpi \u001b[38;5;241m=\u001b[39m \u001b[43mspo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m Ires \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mceil(k \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(n)))):\n",
      "\u001b[0;31mTypeError\u001b[0m: linprog() got an unexpected keyword argument 'integrality'"
     ]
    }
   ],
   "source": [
    "setCover(I, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5f7c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linprog in module scipy.optimize._linprog:\n",
      "\n",
      "linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None, method='interior-point', callback=None, options=None, x0=None)\n",
      "    Linear programming: minimize a linear objective function subject to linear\n",
      "    equality and inequality constraints.\n",
      "    \n",
      "    Linear programming solves problems of the following form:\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "        \\min_x \\ & c^T x \\\\\n",
      "        \\mbox{such that} \\ & A_{ub} x \\leq b_{ub},\\\\\n",
      "        & A_{eq} x = b_{eq},\\\\\n",
      "        & l \\leq x \\leq u ,\n",
      "    \n",
      "    where :math:`x` is a vector of decision variables; :math:`c`,\n",
      "    :math:`b_{ub}`, :math:`b_{eq}`, :math:`l`, and :math:`u` are vectors; and\n",
      "    :math:`A_{ub}` and :math:`A_{eq}` are matrices.\n",
      "    \n",
      "    Alternatively, that's:\n",
      "    \n",
      "    minimize::\n",
      "    \n",
      "        c @ x\n",
      "    \n",
      "    such that::\n",
      "    \n",
      "        A_ub @ x <= b_ub\n",
      "        A_eq @ x == b_eq\n",
      "        lb <= x <= ub\n",
      "    \n",
      "    Note that by default ``lb = 0`` and ``ub = None`` unless specified with\n",
      "    ``bounds``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    c : 1-D array\n",
      "        The coefficients of the linear objective function to be minimized.\n",
      "    A_ub : 2-D array, optional\n",
      "        The inequality constraint matrix. Each row of ``A_ub`` specifies the\n",
      "        coefficients of a linear inequality constraint on ``x``.\n",
      "    b_ub : 1-D array, optional\n",
      "        The inequality constraint vector. Each element represents an\n",
      "        upper bound on the corresponding value of ``A_ub @ x``.\n",
      "    A_eq : 2-D array, optional\n",
      "        The equality constraint matrix. Each row of ``A_eq`` specifies the\n",
      "        coefficients of a linear equality constraint on ``x``.\n",
      "    b_eq : 1-D array, optional\n",
      "        The equality constraint vector. Each element of ``A_eq @ x`` must equal\n",
      "        the corresponding element of ``b_eq``.\n",
      "    bounds : sequence, optional\n",
      "        A sequence of ``(min, max)`` pairs for each element in ``x``, defining\n",
      "        the minimum and maximum values of that decision variable. Use ``None``\n",
      "        to indicate that there is no bound. By default, bounds are\n",
      "        ``(0, None)`` (all decision variables are non-negative).\n",
      "        If a single tuple ``(min, max)`` is provided, then ``min`` and\n",
      "        ``max`` will serve as bounds for all decision variables.\n",
      "    method : str, optional\n",
      "        The algorithm used to solve the standard form problem.\n",
      "        :ref:`'highs-ds' <optimize.linprog-highs-ds>`,\n",
      "        :ref:`'highs-ipm' <optimize.linprog-highs-ipm>`,\n",
      "        :ref:`'highs' <optimize.linprog-highs>`,\n",
      "        :ref:`'interior-point' <optimize.linprog-interior-point>` (default),\n",
      "        :ref:`'revised simplex' <optimize.linprog-revised_simplex>`, and\n",
      "        :ref:`'simplex' <optimize.linprog-simplex>` (legacy)\n",
      "        are supported.\n",
      "    callback : callable, optional\n",
      "        If a callback function is provided, it will be called at least once per\n",
      "        iteration of the algorithm. The callback function must accept a single\n",
      "        `scipy.optimize.OptimizeResult` consisting of the following fields:\n",
      "    \n",
      "        x : 1-D array\n",
      "            The current solution vector.\n",
      "        fun : float\n",
      "            The current value of the objective function ``c @ x``.\n",
      "        success : bool\n",
      "            ``True`` when the algorithm has completed successfully.\n",
      "        slack : 1-D array\n",
      "            The (nominally positive) values of the slack,\n",
      "            ``b_ub - A_ub @ x``.\n",
      "        con : 1-D array\n",
      "            The (nominally zero) residuals of the equality constraints,\n",
      "            ``b_eq - A_eq @ x``.\n",
      "        phase : int\n",
      "            The phase of the algorithm being executed.\n",
      "        status : int\n",
      "            An integer representing the status of the algorithm.\n",
      "    \n",
      "            ``0`` : Optimization proceeding nominally.\n",
      "    \n",
      "            ``1`` : Iteration limit reached.\n",
      "    \n",
      "            ``2`` : Problem appears to be infeasible.\n",
      "    \n",
      "            ``3`` : Problem appears to be unbounded.\n",
      "    \n",
      "            ``4`` : Numerical difficulties encountered.\n",
      "    \n",
      "            nit : int\n",
      "                The current iteration number.\n",
      "            message : str\n",
      "                A string descriptor of the algorithm status.\n",
      "    \n",
      "        Callback functions are not currently supported by the HiGHS methods.\n",
      "    \n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        options:\n",
      "    \n",
      "        maxiter : int\n",
      "            Maximum number of iterations to perform.\n",
      "            Default: see method-specific documentation.\n",
      "        disp : bool\n",
      "            Set to ``True`` to print convergence messages.\n",
      "            Default: ``False``.\n",
      "        presolve : bool\n",
      "            Set to ``False`` to disable automatic presolve.\n",
      "            Default: ``True``.\n",
      "    \n",
      "        All methods except the HiGHS solvers also accept:\n",
      "    \n",
      "        tol : float\n",
      "            A tolerance which determines when a residual is \"close enough\" to\n",
      "            zero to be considered exactly zero.\n",
      "        autoscale : bool\n",
      "            Set to ``True`` to automatically perform equilibration.\n",
      "            Consider using this option if the numerical values in the\n",
      "            constraints are separated by several orders of magnitude.\n",
      "            Default: ``False``.\n",
      "        rr : bool\n",
      "            Set to ``False`` to disable automatic redundancy removal.\n",
      "            Default: ``True``.\n",
      "        rr_method : string\n",
      "            Method used to identify and remove redundant rows from the\n",
      "            equality constraint matrix after presolve. For problems with\n",
      "            dense input, the available methods for redundancy removal are:\n",
      "    \n",
      "            \"SVD\":\n",
      "                Repeatedly performs singular value decomposition on\n",
      "                the matrix, detecting redundant rows based on nonzeros\n",
      "                in the left singular vectors that correspond with\n",
      "                zero singular values. May be fast when the matrix is\n",
      "                nearly full rank.\n",
      "            \"pivot\":\n",
      "                Uses the algorithm presented in [5]_ to identify\n",
      "                redundant rows.\n",
      "            \"ID\":\n",
      "                Uses a randomized interpolative decomposition.\n",
      "                Identifies columns of the matrix transpose not used in\n",
      "                a full-rank interpolative decomposition of the matrix.\n",
      "            None:\n",
      "                Uses \"svd\" if the matrix is nearly full rank, that is,\n",
      "                the difference between the matrix rank and the number\n",
      "                of rows is less than five. If not, uses \"pivot\". The\n",
      "                behavior of this default is subject to change without\n",
      "                prior notice.\n",
      "    \n",
      "            Default: None.\n",
      "            For problems with sparse input, this option is ignored, and the\n",
      "            pivot-based algorithm presented in [5]_ is used.\n",
      "    \n",
      "        For method-specific options, see\n",
      "        :func:`show_options('linprog') <show_options>`.\n",
      "    \n",
      "    x0 : 1-D array, optional\n",
      "        Guess values of the decision variables, which will be refined by\n",
      "        the optimization algorithm. This argument is currently used only by the\n",
      "        'revised simplex' method, and can only be used if `x0` represents a\n",
      "        basic feasible solution.\n",
      "    \n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        A :class:`scipy.optimize.OptimizeResult` consisting of the fields:\n",
      "    \n",
      "        x : 1-D array\n",
      "            The values of the decision variables that minimizes the\n",
      "            objective function while satisfying the constraints.\n",
      "        fun : float\n",
      "            The optimal value of the objective function ``c @ x``.\n",
      "        slack : 1-D array\n",
      "            The (nominally positive) values of the slack variables,\n",
      "            ``b_ub - A_ub @ x``.\n",
      "        con : 1-D array\n",
      "            The (nominally zero) residuals of the equality constraints,\n",
      "            ``b_eq - A_eq @ x``.\n",
      "        success : bool\n",
      "            ``True`` when the algorithm succeeds in finding an optimal\n",
      "            solution.\n",
      "        status : int\n",
      "            An integer representing the exit status of the algorithm.\n",
      "    \n",
      "            ``0`` : Optimization terminated successfully.\n",
      "    \n",
      "            ``1`` : Iteration limit reached.\n",
      "    \n",
      "            ``2`` : Problem appears to be infeasible.\n",
      "    \n",
      "            ``3`` : Problem appears to be unbounded.\n",
      "    \n",
      "            ``4`` : Numerical difficulties encountered.\n",
      "    \n",
      "        nit : int\n",
      "            The total number of iterations performed in all phases.\n",
      "        message : str\n",
      "            A string descriptor of the exit status of the algorithm.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    show_options : Additional options accepted by the solvers.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter.\n",
      "    \n",
      "    `'highs-ds'` and\n",
      "    `'highs-ipm'` are interfaces to the\n",
      "    HiGHS simplex and interior-point method solvers [13]_, respectively.\n",
      "    `'highs'` chooses between\n",
      "    the two automatically. These are the fastest linear\n",
      "    programming solvers in SciPy, especially for large, sparse problems;\n",
      "    which of these two is faster is problem-dependent.\n",
      "    `'interior-point'` is the default\n",
      "    as it was the fastest and most robust method before the recent\n",
      "    addition of the HiGHS solvers.\n",
      "    `'revised simplex'` is more\n",
      "    accurate than interior-point for the problems it solves.\n",
      "    `'simplex'` is the legacy method and is\n",
      "    included for backwards compatibility and educational purposes.\n",
      "    \n",
      "    Method *highs-ds* is a wrapper of the C++ high performance dual\n",
      "    revised simplex implementation (HSOL) [13]_, [14]_. Method *highs-ipm*\n",
      "    is a wrapper of a C++ implementation of an **i**\\ nterior-\\ **p**\\ oint\n",
      "    **m**\\ ethod [13]_; it features a crossover routine, so it is as accurate\n",
      "    as a simplex solver. Method *highs* chooses between the two automatically.\n",
      "    For new code involving `linprog`, we recommend explicitly choosing one of\n",
      "    these three method values.\n",
      "    \n",
      "    .. versionadded:: 1.6.0\n",
      "    \n",
      "    Method *interior-point* uses the primal-dual path following algorithm\n",
      "    as outlined in [4]_. This algorithm supports sparse constraint matrices and\n",
      "    is typically faster than the simplex methods, especially for large, sparse\n",
      "    problems. Note, however, that the solution returned may be slightly less\n",
      "    accurate than those of the simplex methods and will not, in general,\n",
      "    correspond with a vertex of the polytope defined by the constraints.\n",
      "    \n",
      "    .. versionadded:: 1.0.0\n",
      "    \n",
      "    Method *revised simplex* uses the revised simplex method as described in\n",
      "    [9]_, except that a factorization [11]_ of the basis matrix, rather than\n",
      "    its inverse, is efficiently maintained and used to solve the linear systems\n",
      "    at each iteration of the algorithm.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Method *simplex* uses a traditional, full-tableau implementation of\n",
      "    Dantzig's simplex algorithm [1]_, [2]_ (*not* the\n",
      "    Nelder-Mead simplex). This algorithm is included for backwards\n",
      "    compatibility and educational purposes.\n",
      "    \n",
      "    .. versionadded:: 0.15.0\n",
      "    \n",
      "    Before applying *interior-point*, *revised simplex*, or *simplex*,\n",
      "    a presolve procedure based on [8]_ attempts\n",
      "    to identify trivial infeasibilities, trivial unboundedness, and potential\n",
      "    problem simplifications. Specifically, it checks for:\n",
      "    \n",
      "    - rows of zeros in ``A_eq`` or ``A_ub``, representing trivial constraints;\n",
      "    - columns of zeros in ``A_eq`` `and` ``A_ub``, representing unconstrained\n",
      "      variables;\n",
      "    - column singletons in ``A_eq``, representing fixed variables; and\n",
      "    - column singletons in ``A_ub``, representing simple bounds.\n",
      "    \n",
      "    If presolve reveals that the problem is unbounded (e.g. an unconstrained\n",
      "    and unbounded variable has negative cost) or infeasible (e.g., a row of\n",
      "    zeros in ``A_eq`` corresponds with a nonzero in ``b_eq``), the solver\n",
      "    terminates with the appropriate status code. Note that presolve terminates\n",
      "    as soon as any sign of unboundedness is detected; consequently, a problem\n",
      "    may be reported as unbounded when in reality the problem is infeasible\n",
      "    (but infeasibility has not been detected yet). Therefore, if it is\n",
      "    important to know whether the problem is actually infeasible, solve the\n",
      "    problem again with option ``presolve=False``.\n",
      "    \n",
      "    If neither infeasibility nor unboundedness are detected in a single pass\n",
      "    of the presolve, bounds are tightened where possible and fixed\n",
      "    variables are removed from the problem. Then, linearly dependent rows\n",
      "    of the ``A_eq`` matrix are removed, (unless they represent an\n",
      "    infeasibility) to avoid numerical difficulties in the primary solve\n",
      "    routine. Note that rows that are nearly linearly dependent (within a\n",
      "    prescribed tolerance) may also be removed, which can change the optimal\n",
      "    solution in rare cases. If this is a concern, eliminate redundancy from\n",
      "    your problem formulation and run with option ``rr=False`` or\n",
      "    ``presolve=False``.\n",
      "    \n",
      "    Several potential improvements can be made here: additional presolve\n",
      "    checks outlined in [8]_ should be implemented, the presolve routine should\n",
      "    be run multiple times (until no further simplifications can be made), and\n",
      "    more of the efficiency improvements from [5]_ should be implemented in the\n",
      "    redundancy removal routines.\n",
      "    \n",
      "    After presolve, the problem is transformed to standard form by converting\n",
      "    the (tightened) simple bounds to upper bound constraints, introducing\n",
      "    non-negative slack variables for inequality constraints, and expressing\n",
      "    unbounded variables as the difference between two non-negative variables.\n",
      "    Optionally, the problem is automatically scaled via equilibration [12]_.\n",
      "    The selected algorithm solves the standard form problem, and a\n",
      "    postprocessing routine converts the result to a solution to the original\n",
      "    problem.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Dantzig, George B., Linear programming and extensions. Rand\n",
      "           Corporation Research Study Princeton Univ. Press, Princeton, NJ,\n",
      "           1963\n",
      "    .. [2] Hillier, S.H. and Lieberman, G.J. (1995), \"Introduction to\n",
      "           Mathematical Programming\", McGraw-Hill, Chapter 4.\n",
      "    .. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n",
      "           Mathematics of Operations Research (2), 1977: pp. 103-107.\n",
      "    .. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n",
      "           optimizer for linear programming: an implementation of the\n",
      "           homogeneous algorithm.\" High performance optimization. Springer US,\n",
      "           2000. 197-232.\n",
      "    .. [5] Andersen, Erling D. \"Finding all linearly dependent rows in\n",
      "           large-scale linear programming.\" Optimization Methods and Software\n",
      "           6.3 (1995): 219-227.\n",
      "    .. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n",
      "           Programming based on Newton's Method.\" Unpublished Course Notes,\n",
      "           March 2004. Available 2/25/2017 at\n",
      "           https://ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n",
      "    .. [7] Fourer, Robert. \"Solving Linear Programs by Interior-Point Methods.\"\n",
      "           Unpublished Course Notes, August 26, 2005. Available 2/25/2017 at\n",
      "           http://www.4er.org/CourseNotes/Book%20B/B-III.pdf\n",
      "    .. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n",
      "           programming.\" Mathematical Programming 71.2 (1995): 221-245.\n",
      "    .. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n",
      "           programming.\" Athena Scientific 1 (1997): 997.\n",
      "    .. [10] Andersen, Erling D., et al. Implementation of interior point\n",
      "            methods for large scale linear programming. HEC/Universite de\n",
      "            Geneve, 1996.\n",
      "    .. [11] Bartels, Richard H. \"A stabilization of the simplex method.\"\n",
      "            Journal in  Numerische Mathematik 16.5 (1971): 414-434.\n",
      "    .. [12] Tomlin, J. A. \"On scaling linear programming problems.\"\n",
      "            Mathematical Programming Study 4 (1975): 146-166.\n",
      "    .. [13] Huangfu, Q., Galabova, I., Feldmeier, M., and Hall, J. A. J.\n",
      "            \"HiGHS - high performance software for linear optimization.\"\n",
      "            Accessed 4/16/2020 at https://www.maths.ed.ac.uk/hall/HiGHS/#guide\n",
      "    .. [14] Huangfu, Q. and Hall, J. A. J. \"Parallelizing the dual revised\n",
      "            simplex method.\" Mathematical Programming Computation, 10 (1),\n",
      "            119-142, 2018. DOI: 10.1007/s12532-017-0130-5\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Consider the following problem:\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "        \\min_{x_0, x_1} \\ -x_0 + 4x_1 & \\\\\n",
      "        \\mbox{such that} \\ -3x_0 + x_1 & \\leq 6,\\\\\n",
      "        -x_0 - 2x_1 & \\geq -4,\\\\\n",
      "        x_1 & \\geq -3.\n",
      "    \n",
      "    The problem is not presented in the form accepted by `linprog`. This is\n",
      "    easily remedied by converting the \"greater than\" inequality\n",
      "    constraint to a \"less than\" inequality constraint by\n",
      "    multiplying both sides by a factor of :math:`-1`. Note also that the last\n",
      "    constraint is really the simple bound :math:`-3 \\leq x_1 \\leq \\infty`.\n",
      "    Finally, since there are no bounds on :math:`x_0`, we must explicitly\n",
      "    specify the bounds :math:`-\\infty \\leq x_0 \\leq \\infty`, as the\n",
      "    default is for variables to be non-negative. After collecting coeffecients\n",
      "    into arrays and tuples, the input for this problem is:\n",
      "    \n",
      "    >>> c = [-1, 4]\n",
      "    >>> A = [[-3, 1], [1, 2]]\n",
      "    >>> b = [6, 4]\n",
      "    >>> x0_bounds = (None, None)\n",
      "    >>> x1_bounds = (-3, None)\n",
      "    >>> from scipy.optimize import linprog\n",
      "    >>> res = linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds])\n",
      "    \n",
      "    Note that the default method for `linprog` is 'interior-point', which is\n",
      "    approximate by nature.\n",
      "    \n",
      "    >>> print(res)\n",
      "         con: array([], dtype=float64)\n",
      "         fun: -21.99999984082494 # may vary\n",
      "     message: 'Optimization terminated successfully.'\n",
      "         nit: 6 # may vary\n",
      "       slack: array([3.89999997e+01, 8.46872439e-08] # may vary\n",
      "      status: 0\n",
      "     success: True\n",
      "           x: array([ 9.99999989, -2.99999999]) # may vary\n",
      "    \n",
      "    If you need greater accuracy, try 'revised simplex'.\n",
      "    \n",
      "    >>> res = linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds], method='revised simplex')\n",
      "    >>> print(res)\n",
      "         con: array([], dtype=float64)\n",
      "         fun: -22.0 # may vary\n",
      "     message: 'Optimization terminated successfully.'\n",
      "         nit: 1 # may vary\n",
      "       slack: array([39.,  0.]) # may vary\n",
      "      status: 0\n",
      "     success: True\n",
      "           x: array([10., -3.]) # may vary\n",
      "    \n",
      "    You can use the ``options`` parameter, e.g.,\n",
      "    to restrict the maximum number of iterations.\n",
      "    \n",
      "    >>> res = linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds],\n",
      "    ...               options={'maxiter': 4})\n",
      "    >>> print(res)\n",
      "        con: array([], dtype=float64)\n",
      "        fun: -21.35207150630407 # may vary\n",
      "    message: 'The iteration limit was reached before the algorithm converged.'\n",
      "        nit: 4\n",
      "      slack: array([37.19406046,  0.5727398 ])\n",
      "     status: 1\n",
      "    success: False\n",
      "          x: array([ 9.4021973 , -2.98746855])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spo.linprog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dce1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=generateInstance(4, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1529ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "X=setCover(I, 1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "164e03d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universe = set.union(*[e for e,w in I])\n",
    "set.union(*[I[i][0] for i in X]) == universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93521d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
